{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Crawling__Selenium.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbptHXvnavbt"
      },
      "source": [
        "def data_crawling(year):\n",
        "  # Parameter\n",
        "  # 원하는 연도 입력\n",
        "  year = year\n",
        "  # 데이터를 수집할 타자 중 타석 수 상위 명수\n",
        "  num_top_batter = 30\n",
        "\n",
        "  # Team List\n",
        "  # 원하는 연도에 등록된 팀을 미리 넣어두어야함 (추가 가능)\n",
        "  Team_2016 = ['NC','kt','LG','두산','히어로즈','KIA','롯데','삼성','SK','한화']\n",
        "  Team_2017 = ['NC','kt','LG','두산','히어로즈','KIA','롯데','삼성','SK','한화']\n",
        "  Team_2018 = ['NC','kt','LG','두산','히어로즈','KIA','롯데','삼성','SK','한화']\n",
        "  Team_2019 = ['NC','kt','LG','두산','키움','KIA','롯데','삼성','SK','한화']\n",
        "  Team_2020 = ['NC','kt','LG','두산','키움','KIA','롯데','삼성','SK','한화']\n",
        "  Team_2021 = ['kt','삼성','LG','SSG','NC','키움','두산','롯데','KIA','한화']\n",
        "\n",
        "  # Team Dictionary\n",
        "  # Team List를 딕셔너리에 넣음 (추가 가능)\n",
        "  TeamDic = {'2016':Team_2016, '2017':Team_2017, '2018':Team_2018, '2019':Team_2019, '2020':Team_2020, '2021':Team_2021}\n",
        "\n",
        "  ###############\n",
        "  # BeautifulSoup\n",
        "\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import requests\n",
        "  from bs4 import BeautifulSoup\n",
        "  from tqdm import tqdm\n",
        "\n",
        "  # 데이터를 모을 dataframe 생성\n",
        "  data = pd.DataFrame(columns=['day', 'vs', 'inn', 'pitcher', 'batter', 'P', 'result', 'before', 'after', 'LEV', 'REa', 'WPs','WPe', 'WPa'])\n",
        "  batter_data = pd.DataFrame(columns=['Team','name'])\n",
        "\n",
        "  for Team in tqdm(TeamDic[str(year)]): # 선택한 연도의 팀을 하나씩 가져옴\n",
        "    # 스탯티즈 시즌기록실 페이지에서 연도, 팀 선택하고, 타석순으로 정렬\n",
        "    wp = requests.get(\"http://www.statiz.co.kr/stat.php?opt=0&sopt=0&re=0&ys=\" + str(year) + \"&ye=\" + str(year) + \"&se=0&te=\" + Team + \"&tm=&ty=0&qu=auto&po=0&as=&ae=&hi=&un=&pl=&da=1&o1=TPA&o2=TPA&de=1&lr=0&tr=&cv=&ml=1&sn=30&si=&cn=\")\n",
        "    soup = BeautifulSoup(wp.text, \"html.parser\")\n",
        "    \n",
        "    # 현재 팀의 타석 수 상위 num_top_batter 명\n",
        "    tmp_batter_list = np.empty(num_top_batter,dtype=object)\n",
        "    tmp_team = np.array([Team]*num_top_batter) # 타석 수 상위 타자 팀명 저장\n",
        "    tmp_batter_list_href = np.empty(num_top_batter,dtype=object)\n",
        "    tmp_batter_ps=0\n",
        "    \n",
        "    for batter in soup.find_all('tr')[2:12]:\n",
        "      tmp_batter_list[tmp_batter_ps] = batter.find_all('td')[1].text # 타석 수 상위 타자 이름 저장\n",
        "      tmp_team[tmp_batter_ps] = Team\n",
        "      tmp_batter_list_href[tmp_batter_ps] = batter.find_all('a')[0].attrs['href'] # 타석 수 상위 타자 주소 저장\n",
        "      tmp_batter_ps+=1\n",
        "\n",
        "    for batter in soup.find_all('tr')[14:24]:\n",
        "      tmp_batter_list[tmp_batter_ps] = batter.find_all('td')[1].text # 타석 수 상위 타자 이름 저장\n",
        "      tmp_team[tmp_batter_ps] = Team\n",
        "      tmp_batter_list_href[tmp_batter_ps] = batter.find_all('a')[0].attrs['href'] # 타석 수 상위 타자 주소 저장\n",
        "      tmp_batter_ps+=1\n",
        "\n",
        "    for batter in soup.find_all('tr')[26:36]:\n",
        "      if '|' in batter.find_all('td')[1].text:\n",
        "        break;\n",
        "      else:\n",
        "        tmp_batter_list[tmp_batter_ps] = batter.find_all('td')[1].text # 타석 수 상위 타자 이름 저장\n",
        "        tmp_team[tmp_batter_ps] = Team\n",
        "        tmp_batter_list_href[tmp_batter_ps] = batter.find_all('a')[0].attrs['href'] # 타석 수 상위 타자 주소 저장\n",
        "        tmp_batter_ps+=1\n",
        "\n",
        "    batter_data = pd.concat([batter_data, pd.DataFrame({'Team':tmp_team, 'name':tmp_batter_list})])\n",
        "\n",
        "    # 타석 수 상위 타자들 중 한명씩 데이터를 모으는 과정\n",
        "    for top_batter in range(num_top_batter):\n",
        "      if tmp_batter_list[top_batter] is None:\n",
        "        continue\n",
        "\n",
        "      wp=requests.get(\"http://www.statiz.co.kr/\"+tmp_batter_list_href[top_batter]) # 타자 주소로 접근\n",
        "      soup=BeautifulSoup(wp.text, \"html.parser\")\n",
        "\n",
        "      # playlog 데이터로 접근\n",
        "      href_by_playlog = soup.select('body > div > div.content-wrapper > div > section.content > div > div:nth-of-type(1) > div > div.col-xs-12.col-sm-8.col-md-8.col-lg-12 > div > div.table-responsive.no-padding.box > table')[0].find_all('a')[6].attrs['href']\n",
        "      wp=requests.get(\"http://www.statiz.co.kr/\"+href_by_playlog)\n",
        "      soup=BeautifulSoup(wp.text,\"html.parser\")\n",
        "\n",
        "      # 타자/투수 : 타자로 접근\n",
        "      href_by_batter=soup.select('body > div.wrapper > div.content-wrapper > div > section.content > div > div:nth-of-type(2) > div > div:nth-of-type(1) > div:nth-of-type(1)')[0].find_all('a')[0].attrs['href']\n",
        "      wp=requests.get(\"http://www.statiz.co.kr/\"+href_by_batter)\n",
        "      soup=BeautifulSoup(wp.text,\"html.parser\")\n",
        "\n",
        "      # year : 원하는 연도로 접근\n",
        "      try:\n",
        "        href_byDate_year=soup.select('body > div.wrapper > div.content-wrapper > div > section.content > div > div:nth-of-type(2) > div > div:nth-of-type(1) > div:nth-of-type(2)')[0].find('a', text=str(year)).attrs['href']\n",
        "        wp=requests.get(\"http://www.statiz.co.kr/\"+href_byDate_year)\n",
        "        soup=BeautifulSoup(wp.text,\"html.parser\")\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      # WPA에서 타석으로 접근\n",
        "      href_by_ab = soup.select('body > div > div.content-wrapper > div > section.content > div > div:nth-of-type(2) > div > div:nth-of-type(3) > div')[0].find_all('a')[1].attrs['href']\n",
        "      wp=requests.get(\"http://www.statiz.co.kr/\"+href_by_ab)\n",
        "      soup=BeautifulSoup(wp.text,\"html.parser\")\n",
        "\n",
        "      ## 데이터가 있는 페이지로 이동 완료\n",
        "      ## 이제 실질적인 데이터를 모을 차례\n",
        "      rawdata = soup.find_all(class_='table table-striped table-responsive table-condensed table-bordered')[0]\n",
        "      # rawdata : 전체 테이블\n",
        "\n",
        "      # th를 제외한 순수한 경기 데이터 / th는 컬럼명 행이다.\n",
        "      rawdata_not_th = rawdata.find_all('tr',{'class':['oddrow_stz','evenrow_stz']})\n",
        "\n",
        "      # 행렬만들기\n",
        "      rawdata_day = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_vs = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_inn = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_pitcher = np.zeros(len(rawdata_not_th),dtype=object)\n",
        "      rawdata_batter = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_P = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_result = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_before = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_after = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_LEV = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_REa = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_WPs = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_WPe = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "      rawdata_WPa = np.zeros(len(rawdata_not_th), dtype=object)\n",
        "\n",
        "      for rawdata_not_th_tr_index in range(len(rawdata_not_th)):\n",
        "        # 한 행 : rawdata_not_th_tr_index\n",
        "        rawdata_not_th_td = [text for text in rawdata_not_th[rawdata_not_th_tr_index].stripped_strings]\n",
        "        # 현재 행의 하나의 값 : rawdata_not_th_td[index]\n",
        "        # 데이터 입력\n",
        "        if len(rawdata_not_th_td) == 14:\n",
        "          rawdata_day[rawdata_not_th_tr_index] = rawdata_not_th_td[0]\n",
        "          rawdata_vs[rawdata_not_th_tr_index] = rawdata_not_th_td[1]\n",
        "          rawdata_inn[rawdata_not_th_tr_index] = rawdata_not_th_td[2]\n",
        "          rawdata_pitcher[rawdata_not_th_tr_index] = rawdata_not_th_td[3]\n",
        "          rawdata_batter[rawdata_not_th_tr_index] = rawdata_not_th_td[5]\n",
        "          rawdata_P[rawdata_not_th_tr_index] = \"\"\n",
        "          rawdata_result[rawdata_not_th_tr_index] = rawdata_not_th_td[6]\n",
        "          rawdata_before[rawdata_not_th_tr_index] = rawdata_not_th_td[7]\n",
        "          rawdata_after[rawdata_not_th_tr_index] = rawdata_not_th_td[8]\n",
        "          rawdata_LEV[rawdata_not_th_tr_index] = rawdata_not_th_td[9]\n",
        "          rawdata_REa[rawdata_not_th_tr_index] = rawdata_not_th_td[10]\n",
        "          rawdata_WPs[rawdata_not_th_tr_index] = rawdata_not_th_td[11]\n",
        "          rawdata_WPe[rawdata_not_th_tr_index] = rawdata_not_th_td[12]\n",
        "          rawdata_WPa[rawdata_not_th_tr_index] = rawdata_not_th_td[13]\n",
        "        else:\n",
        "          rawdata_day[rawdata_not_th_tr_index] = rawdata_not_th_td[0]\n",
        "          rawdata_vs[rawdata_not_th_tr_index] = rawdata_not_th_td[1]\n",
        "          rawdata_inn[rawdata_not_th_tr_index] = rawdata_not_th_td[2]\n",
        "          rawdata_pitcher[rawdata_not_th_tr_index] = rawdata_not_th_td[3]\n",
        "          rawdata_batter[rawdata_not_th_tr_index] = rawdata_not_th_td[5]\n",
        "          rawdata_P[rawdata_not_th_tr_index] = rawdata_not_th_td[6]\n",
        "          rawdata_result[rawdata_not_th_tr_index] = rawdata_not_th_td[7]\n",
        "          rawdata_before[rawdata_not_th_tr_index] = rawdata_not_th_td[8]\n",
        "          rawdata_after[rawdata_not_th_tr_index] = rawdata_not_th_td[9]\n",
        "          rawdata_LEV[rawdata_not_th_tr_index] = rawdata_not_th_td[10]\n",
        "          rawdata_REa[rawdata_not_th_tr_index] = rawdata_not_th_td[11]\n",
        "          rawdata_WPs[rawdata_not_th_tr_index] = rawdata_not_th_td[12]\n",
        "          rawdata_WPe[rawdata_not_th_tr_index] = rawdata_not_th_td[13]\n",
        "          rawdata_WPa[rawdata_not_th_tr_index] = rawdata_not_th_td[14]\n",
        "\n",
        "      tmp_data = pd.DataFrame()\n",
        "      # tmp_data는 각 선수마다 데이터를 모은 후 data에 머지하기 전에 존재\n",
        "      tmp_data['day'] = rawdata_day\n",
        "      tmp_data['vs'] = rawdata_vs\n",
        "      tmp_data['inn'] = rawdata_inn\n",
        "      tmp_data['pitcher'] = rawdata_pitcher\n",
        "      tmp_data['batter'] = rawdata_batter\n",
        "      tmp_data['P'] = rawdata_P\n",
        "      tmp_data['result'] = rawdata_result\n",
        "      tmp_data['before'] = rawdata_before\n",
        "      tmp_data['after'] = rawdata_after\n",
        "      tmp_data['LEV'] = rawdata_LEV\n",
        "      tmp_data['REa'] = rawdata_REa\n",
        "      tmp_data['WPs'] = rawdata_WPs\n",
        "      tmp_data['WPe'] = rawdata_WPe\n",
        "      tmp_data['WPa'] = rawdata_WPa\n",
        "\n",
        "      # 데이터 쌓기\n",
        "      data = pd.concat([data,tmp_data])\n",
        "\n",
        "  return data,batter_data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCjG-tR7yiWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bd3850-5c65-42a0-be79-baef84f157ac"
      },
      "source": [
        "data_2021, batter_data_2021 = data_crawling(2021)\n",
        "data_2021.to_csv(\"data_2021.csv\", encoding='euc-kr', index=False)\n",
        "batter_data_2021.to_csv(\"batter_data_2021.csv\", encoding='euc-kr', index=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [28:30<00:00, 171.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyxXYThI84_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a182664-d626-4ff6-fb35-37d4a2bbb803"
      },
      "source": [
        "data_2020, batter_data_2020 = data_crawling(2020)\n",
        "data_2020.to_csv(\"data_2020.csv\", encoding='euc-kr', index=False)\n",
        "batter_data_2020.to_csv(\"batter_data_2020.csv\", encoding='euc-kr', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [34:58<00:00, 209.90s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyzc4a5TVusD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e815f7-b135-4aa3-dce2-dc53ed038be4"
      },
      "source": [
        "data_2019, batter_data_2019 = data_crawling(2019)\n",
        "data_2019.to_csv(\"data_2019.csv\", encoding='euc-kr', index=False)\n",
        "batter_data_2019.to_csv(\"batter_data_2019.csv\", encoding='euc-kr', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [36:22<00:00, 218.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJQQbL5shXLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a976315-16c4-4c97-f2cd-75efd044913b"
      },
      "source": [
        "data_2018, batter_data_2018 = data_crawling(2018)\n",
        "data_2018.to_csv(\"data_2018.csv\", encoding='euc-kr', index=False)\n",
        "batter_data_2018.to_csv(\"batter_data_2018.csv\", encoding='euc-kr', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [37:31<00:00, 225.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
